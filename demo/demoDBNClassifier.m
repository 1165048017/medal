fprintf('\nHere we train a Deep Belief Network on the\n')
fprintf('\nMNIST datastet.\n');

args = {'type','BB' , ...
		'nHid', [100, 100,10] ...
		'verbose', 1, ...
		'eta', [0.1,0.1,0.05] ...
		'momentum', 0.5, ...
		'nEpoch', [50, 100, 100,] ...
		'wDecay', 0.002, ...
		'batchSz', 100, ...
		'anneal', 1, ...
		'varyEta',[0,0,1], ...
		'classify',1, ...
		'nGibbs', 1};

d = dbn(args); % STACK A DEFAULT DBN


figure(1);
for iL = 1:d.nLayers
	subplot(1,d.nLayers,iL);
	d.layers{iL}.vis(); title(sprintf('Layer %d Weights',iL));drawnow
end

% TEST CLASSIFICATION ON HOLD-OUT SET
load('defaultData.mat','testdata','testlabels');
[pred,classErr,misClass] = d.predictClass(testdata,testlabels);

figure(2);
d.layers{1}.vis(testdata(misClass,:)');
title(sprintf('Misclassifications\n(Error rate = %2.2f%%)',classErr*100));
